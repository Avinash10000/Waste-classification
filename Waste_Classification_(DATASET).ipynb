{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Waste Classification (DATASET).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTGtd1I3CYyQ7DMC5ila6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avinash10000/Waste-classification/blob/master/Waste_Classification_(DATASET).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJdTfjRYy6eY",
        "outputId": "3434035c-249e-4223-868e-b3da52efd5b2"
      },
      "source": [
        "import numpy as np\n",
        "#matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from PIL import Image\n",
        "train_path = '../DATASET/TRAIN'\n",
        "test_path = '../DATASET/TEST'\n",
        "IMG_BREDTH = 30\n",
        "IMG_HEIGHT = 60\n",
        "num_classes = 2\n",
        "In [3]\n",
        "train_batch = ImageDataGenerator(featurewise_center=False,\n",
        "                                 samplewise_center=False, \n",
        "                                 featurewise_std_normalization=False, \n",
        "                                 samplewise_std_normalization=False, \n",
        "                                 zca_whitening=False, \n",
        "                                 rotation_range=45, \n",
        "                                 width_shift_range=0.2, \n",
        "                                 height_shift_range=0.2, \n",
        "                                 horizontal_flip=True, \n",
        "                                 vertical_flip=False).flow_from_directory(train_path, \n",
        "                                                                          target_size=(IMG_HEIGHT, IMG_BREDTH), \n",
        "                                                                          classes=['O', 'R'], \n",
        "                                                                          batch_size=100)\n",
        "\n",
        "test_batch = ImageDataGenerator().flow_from_directory(test_path, \n",
        "                                                      target_size=(IMG_HEIGHT, IMG_BREDTH), \n",
        "                                                      classes=['O', 'R'], \n",
        "                                                      batch_size=100)\n",
        "\n",
        "In [4]\n",
        "def cnn_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(IMG_HEIGHT,IMG_BREDTH,3)))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "              \n",
        "    model.summary()\n",
        "              \n",
        "    return model\n",
        "\n",
        "def use_model(path):\n",
        "    \n",
        "    model = load_model('best_waste_classifier.h5')\n",
        "    pic = plt.imread(path)\n",
        "    pic = cv2.resize(pic, (IMG_BREDTH, IMG_HEIGHT))\n",
        "    pic = np.expand_dims(pic, axis=0)\n",
        "    classes = model.predict_classes(pic)\n",
        "    \n",
        "#     code using PIL\n",
        "#     model = load_model('best_waste_classifier.h5')\n",
        "#     pic1 = plt.imread(path)\n",
        "#     pic = Image.open(path).resize((IMG_BREDTH, IMG_HEIGHT))\n",
        "#     plt.imshow(pic1)\n",
        "#     if model.predict_classes(np.expand_dims(pic, axis=0)) == 0:\n",
        "#         classes = 'ORGANIC'\n",
        "#     elif model.predict_classes(np.expand_dims(pic, axis=0)) == 1:\n",
        "#         classes = 'RECYCLABLE'\n",
        "    \n",
        "    return classes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}